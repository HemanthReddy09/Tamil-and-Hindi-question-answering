# Tamil-and-Hindi-question-answering

### Team Members:
      1.	Hemanth Reddy Yerramreddy 
      2.	Chandrakanth Mandalapu
      3.	Mani Renukuntla
      4.	Sathvik Reddy Gutha
      

### Motivation:

The reason for taking up this project is that, in general, questions from foreign languages receive very little attention, or even if answers to these questions exist in the open source, they are not directed towards these questions as they are framed in a native or a colloquial language. To bridge this gap between knowledge transfer of existing ideas, the concept of machine translation is used. Machine translation is a concept of natural language processing that would convert one input language into another output language without the requirement of human interference in between. The purpose of this technique is that the process is automatic, the meaning of the initial text isnâ€™t altered too much, and the goal of the process is to reproduce the text in another language fluently.

The languages Hindi and Tamil are native to India, but these two languages are spoken in different parts of the country. These questions could be understood only by people who would be able to read their languages, to reach a wider audience and get faster answers to these questions. This would only be possible if use machine translation. The goal of the project does not stop with translating these questions to English alone, and the impetus is to find relevant answers to these questions and predict the answers for each one of them. 

The answers would have to be given in both languages, the original language the question was asked in, and, finally, in English. It would solve the problem of the language barrier between various languages. By working on this project, we intend to use various NLP techniques and state-of-art models to predict the answers and, again, extensive experience while working towards completing this project successfully.

### Objectives

The following are the main goals that this project intends to achieve: 
* Finding a data set that is appropriate and contains the necessary quantity and quality of data is the first step in adequately training a model. 
* Use exploratory data analysis to thoroughly evaluate the provided text data to establish a strong foundation for using various NLP algorithms. At this point, the knowledge and viewpoints should aid in creating a solid model. 
* In the EDA stage,  accurately measure the data set and select the most effective preprocessing method.
* The data set for the model is split between training and testing. 
* Data preparation eliminates null values from the dataset using techniques like tokenization, stemming, and lemmatization. 
* Finally, you can experiment with a few potential models while building the model.  Compare the results of each model to determine which is the most effective. 
* The evaluation metric used in this study is a Bilingual Assessment Study or BELU. Due to their ability to accurately score matches with automatically translated language, these scoring models are widely used. 
* Lastly, predict the answer to the question accurately.
