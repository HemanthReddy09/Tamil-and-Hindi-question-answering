{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Sequence to Sequence based Question Answering Model**"
      ],
      "metadata": {
        "id": "uoGD6RTXDu6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install indic-nlp-library\n",
        "!pip install torchtext==0.10.0\n",
        "!pip install deep_translator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Firy0GVpaGuc",
        "outputId": "6a870bb4-f350-4b88-89af-d3bf2bb50a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.81-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Collecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.0.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 90.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from indic-nlp-library) (1.21.6)\n",
            "Collecting sphinx-argparse\n",
            "  Downloading sphinx_argparse-0.3.2-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->indic-nlp-library) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->indic-nlp-library) (1.15.0)\n",
            "Requirement already satisfied: sphinx>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx-argparse->indic-nlp-library) (1.8.6)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.17.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (57.4.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.6.1)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.2.4)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.11.3)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.12)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.10.3)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (21.3)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.0.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.0.9)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\n",
            "Installing collected packages: sphinx-rtd-theme, sphinx-argparse, morfessor, indic-nlp-library\n",
            "Successfully installed indic-nlp-library-0.81 morfessor-2.0.6 sphinx-argparse-0.3.2 sphinx-rtd-theme-1.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 25.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.1)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.9 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.9.24)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deep_translator\n",
            "  Downloading deep_translator-1.9.0-py3-none-any.whl (29 kB)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.9.1\n",
            "  Downloading beautifulsoup4-4.11.1-py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 67.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from deep_translator) (2.23.0)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.3.2.post1-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.0.4)\n",
            "Installing collected packages: soupsieve, beautifulsoup4, deep-translator\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed beautifulsoup4-4.11.1 deep-translator-1.9.0 soupsieve-2.3.2.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Move inside directory**"
      ],
      "metadata": {
        "id": "9iDXd_5Yuzx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"/content/drive/MyDrive/chaii-hindi-and-tamil-question-answering/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy11SDZuZ6jp",
        "outputId": "820f16cc-5fb7-480d-87ed-1bbb6b2d3ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Read dataset**"
      ],
      "metadata": {
        "id": "Z2pNzWmsages"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/chaii-hindi-and-tamil-question-answering/clean_data.csv\", index_col=0, encoding=\"utf-8\")"
      ],
      "metadata": {
        "id": "aF2VghykhoGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Concat question and context**"
      ],
      "metadata": {
        "id": "R_1T5ZWtaJca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def concat_que_context(col):\n",
        "  question = col[0]\n",
        "  context = col[1]\n",
        "  text = question +\" ? \"+ context\n",
        "  return text\n",
        "data['que_context'] = data[['question','context']].apply(concat_que_context, axis=1)"
      ],
      "metadata": {
        "id": "iztcI4-nhz1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Display sample data**"
      ],
      "metadata": {
        "id": "bpKhjKKcaNtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "_bJvR7ipkM3Y",
        "outputId": "0d43fb4f-1cac-4cf5-e848-80f448cfda1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id                                            context  \\\n",
              "0  004938454  இந்தியாவில் வங்கித்தொழில் பதினெட்டாம் நூற்றாண்...   \n",
              "1  9cbe4e227  ऍडविन पावल हबल अंग्रेज़ी edwin powell hubble ज...   \n",
              "\n",
              "                                   question           answer  answer_start  \\\n",
              "0  இந்தியாவில் தாராளமயம் எப்போது தொடங்கியது             1990         10683   \n",
              "1                 एडविन पॉवेल हबल मृत्यु कब  २८ सितम्बर १९५३            79   \n",
              "\n",
              "                                         que_context  \n",
              "0  இந்தியாவில் தாராளமயம் எப்போது தொடங்கியது ? இந்...  \n",
              "1  एडविन पॉवेल हबल मृत्यु कब ? ऍडविन पावल हबल अंग...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b69d45d-a7af-4e3f-9c30-a7a9b4dc7201\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>answer_start</th>\n",
              "      <th>que_context</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>004938454</td>\n",
              "      <td>இந்தியாவில் வங்கித்தொழில் பதினெட்டாம் நூற்றாண்...</td>\n",
              "      <td>இந்தியாவில் தாராளமயம் எப்போது தொடங்கியது</td>\n",
              "      <td>1990</td>\n",
              "      <td>10683</td>\n",
              "      <td>இந்தியாவில் தாராளமயம் எப்போது தொடங்கியது ? இந்...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9cbe4e227</td>\n",
              "      <td>ऍडविन पावल हबल अंग्रेज़ी edwin powell hubble ज...</td>\n",
              "      <td>एडविन पॉवेल हबल मृत्यु कब</td>\n",
              "      <td>२८ सितम्बर १९५३</td>\n",
              "      <td>79</td>\n",
              "      <td>एडविन पॉवेल हबल मृत्यु कब ? ऍडविन पावल हबल अंग...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b69d45d-a7af-4e3f-9c30-a7a9b4dc7201')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0b69d45d-a7af-4e3f-9c30-a7a9b4dc7201 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0b69d45d-a7af-4e3f-9c30-a7a9b4dc7201');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Extract que-context and answer column**"
      ],
      "metadata": {
        "id": "Q7n_HV6ng2Ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['que_context','answer']]"
      ],
      "metadata": {
        "id": "unkA2GyK2q3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(2)"
      ],
      "metadata": {
        "id": "RI5dIsZ12ypl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Check for null values**"
      ],
      "metadata": {
        "id": "sluxGlyZhCH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOj6HtB423c3",
        "outputId": "5073b252-1c3c-4d2c-8f2d-fb6f0db78914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "que_context    0\n",
              "answer         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Split data into train, test and validation**"
      ],
      "metadata": {
        "id": "hcAmDpsBhGhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data.iloc[:914].reset_index(drop=True)\n",
        "test_data = data.iloc[914:1014].reset_index(drop=True)\n",
        "val_data = data.iloc[1014:].reset_index(drop=True)\n",
        "print(\"Train dataset size: \", train_data.shape)\n",
        "print(\"Test dataset size: \", test_data.shape)\n",
        "print(\"Validation dataset size: \", val_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_13aaHIkEAx",
        "outputId": "d4352e78-d706-4a45-c32d-2ecc80dc5723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size:  (914, 2)\n",
            "Test dataset size:  (100, 2)\n",
            "Validation dataset size:  (92, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Import libraries**"
      ],
      "metadata": {
        "id": "zQJhLOr0u_OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import pickle\n",
        "from torchtext import vocab,data\n",
        "from torchtext.vocab import Vectors\n",
        "from torchtext.legacy.data import Field, TabularDataset, BucketIterator, Iterator\n",
        "from indicnlp.tokenize import indic_tokenize \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive\""
      ],
      "metadata": {
        "id": "JIfte404Z6Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Load and process data** "
      ],
      "metadata": {
        "id": "vHz3ZLaTD631"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n8DXV8wYyvw"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_dataset(folder_path,device):\n",
        "  \n",
        "  vec = Vectors(name = 'vec_file.txt', cache = folder_path, unk_init = torch.Tensor.normal_ )\n",
        "  def tokenizer(text):\n",
        "    text = indic_tokenize.trivial_tokenize(text)\n",
        "    return text\n",
        "  # build source text object apply tokenizer\n",
        "  SRC = Field(tokenize=tokenizer,init_token = '<sos>', eos_token = '<eos>',fix_length=384)\n",
        "  # build target text object apply tokenizer\n",
        "  TRG = Field(tokenize=tokenizer,init_token = '<sos>', eos_token = '<eos>',fix_length=30)\n",
        "    \n",
        "  data_fields = [(\"que_context\", SRC),\n",
        "                   (\"answer\", TRG)]\n",
        "  print(folder_path)\n",
        "  train_data, valid_data, test_data = TabularDataset.splits(path=folder_path,  \n",
        "                                            train='train_data.csv', \n",
        "                                            validation='val_data.csv',\n",
        "                                            test='test_data.csv',\n",
        "                                            format='csv', \n",
        "                                            fields=data_fields, \n",
        "                                            skip_header=True)\n",
        "\n",
        "\n",
        "  SRC.build_vocab(train_data,vectors=vec)\n",
        "  TRG.build_vocab(train_data, valid_data, test_data,vectors=vec)\n",
        "\n",
        "  enc_embeddings_weights=SRC.vocab.vectors\n",
        "  dec_embeddings_weights=TRG.vocab.vectors\n",
        "\n",
        "\n",
        "  train_iterator, valid_iterator= BucketIterator.splits((train_data, valid_data), sort_key=lambda x: len(x.que_context), batch_size=4,device=device)\n",
        "  test_iterator = BucketIterator((test_data), batch_size=1,device=device,shuffle=False)\n",
        "\n",
        "   \n",
        "  return SRC, TRG, enc_embeddings_weights, dec_embeddings_weights, train_iterator, valid_iterator, test_iterator, train_data, valid_data, test_data\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Backend available: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LczQNnHGm4T4",
        "outputId": "c562866c-fc2b-4489-e701-b2b790ebbcef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backend available:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SRC, TRG, enc_embeddings_weights, dec_embeddings_weights, train_iterator, valid_iterator, test_iterator,train_data,valid_data, test_data = load_dataset(folder_path,device)\n",
        "\n",
        "print(\"\\n=========================================\")\n",
        "print(\"Total Number of Question_Context-Answer Pairs in Train Data: \",len(train_data))\n",
        "print(\"Total Number of Question_Context-Answer Pairs in Validation Data: \",len(valid_data))\n",
        "print(\"Total Number of Question_Context-Answer Pairs in Test Data: \",len(test_data))\n",
        "print(\"\\n=========================================\")\n",
        "print(\"Total Number of Batches in Train Data: \",len(train_iterator))\n",
        "print(\"Total Number of Batches in Validation Data: \",len(valid_iterator))\n",
        "print(\"Total Number of Batches in Test Data: \",len(test_iterator))\n",
        "print(\"\\n=========================================\")\n",
        "print(\"Highest Frequency Words in Que-Context Vocab \\n\",SRC.vocab.freqs.most_common(10))\n",
        "print(\"\\nHighest Frequency Words in Answer Vocab \\n\",TRG.vocab.freqs.most_common(10))\n",
        "\n",
        "\n",
        "print(f\"\\n\\nSource/Que-Context Vocabulary Size: {len(SRC.vocab)}\")\n",
        "print(f\"Target/Answers Vocabulary Size:   {len(TRG.vocab)}\")\n",
        "source_vocab=SRC.vocab.stoi\n",
        "target_vocab=TRG.vocab.stoi\n",
        "\n",
        "with open(folder_path+'/source_vocab.pickle', 'wb') as src:\n",
        "    pickle.dump(source_vocab, src, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "print(\"Context vocabulary saved successfully....\")\n",
        "with open(folder_path+'/target_vocab.pickle', 'wb') as tgt:\n",
        "    pickle.dump(target_vocab, tgt, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "print(\"Answer vocabulary saved successfully....\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfpulFdymis2",
        "outputId": "a597eb6f-2e50-49a0-b276-2653914d7cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "\n",
            "=========================================\n",
            "Total Number of Question_Context-Answer Pairs in Train Data:  914\n",
            "Total Number of Question_Context-Answer Pairs in Validation Data:  92\n",
            "Total Number of Question_Context-Answer Pairs in Test Data:  100\n",
            "\n",
            "=========================================\n",
            "Total Number of Batches in Train Data:  229\n",
            "Total Number of Batches in Validation Data:  23\n",
            "Total Number of Batches in Test Data:  100\n",
            "\n",
            "=========================================\n",
            "Highest Frequency Words in Que-Context Vocab \n",
            " [('रूप', 3902), ('जाता', 3345), ('तथा', 3052), ('भारत', 2829), ('नाम', 1963), ('भारतीय', 1715), ('समय', 1713), ('उन्होंने', 1687), ('ஆம்', 1602), ('अन्य', 1557)]\n",
            "\n",
            "Highest Frequency Words in Answer Vocab \n",
            " [('किलोमीटर', 15), ('15', 13), ('मीटर', 12), ('जनवरी', 11), ('अक्टूबर', 11), ('अप्रैल', 10), ('7', 9), ('जून', 9), ('सितम्बर', 8), ('18', 8)]\n",
            "\n",
            "\n",
            "Source/Que-Context Vocabulary Size: 149317\n",
            "Target/Answers Vocabulary Size:   1585\n",
            "Context vocabulary saved successfully....\n",
            "Answer vocabulary saved successfully....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Build model architecture**"
      ],
      "metadata": {
        "id": "bILIIo5DEAkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def model_obj(SRC, TRG, enc_embeddings_weights, dec_embeddings_weights, device):\n",
        "  # define encoder model architecture\n",
        "  class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout, weights):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        # make embedding layer\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        # make GRU layer \n",
        "        self.gru = nn.GRU(emb_dim, hid_dim, n_layers, dropout = dropout, bidirectional=True)\n",
        "        # make fully connected layer\n",
        "        self.fc = nn.Linear(hid_dim * 2, hid_dim)\n",
        "        # apply dropout to model\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src):\n",
        "        # appy embedding layer on input data\n",
        "        # apply dropout on embedding vector output\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        # apply gru model on embedding vector\n",
        "        outputs, hidden= self.gru(embedded)\n",
        "        # apply linear layer on data\n",
        "        hidden = self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        hidden=hidden.unsqueeze(0)\n",
        "        # get encoder generated output that will be used as input for decoder\n",
        "        return hidden\n",
        "  # made decoder architecture\n",
        "  class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout,weights):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        \n",
        "        # make embedding layer\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim) \n",
        "        # make gru layer\n",
        "        self.gru = nn.GRU(emb_dim, hid_dim, self.n_layers)    \n",
        "        # make linear \n",
        "        self.out = nn.Linear(hid_dim, output_dim) \n",
        "        # make softmax layer\n",
        "        self.soft = nn.LogSoftmax(dim=1)\n",
        "        # make dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        # appy relu activation function that will smooth generated values\n",
        "        embedded = F.relu(embedded)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        # apply fully connected linear layer\n",
        "        prediction = self.out(output.squeeze(0))\n",
        "        # apply softmax on generated outputs as it will select best form generated ids\n",
        "        prediction = self.soft(prediction)\n",
        "        # prediction are final prediction returned by decoder\n",
        "\n",
        "        return prediction, hidden\n",
        "  # build sequence 2 sequence model architecture that will take encoder and decoder objects and will generate final predictions\n",
        "  class Seq2Seq_GRU(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "    def forward(self, src, trg, truth_chance = 0.8):\n",
        "        # define batch size how many examples will be taken in one iteration\n",
        "        batch_size = trg.shape[1]\n",
        "        # maximum length of answer\n",
        "        max_len = trg.shape[0]\n",
        "        # maximum length of source (que-context)\n",
        "        input_max_len = src.shape[0]\n",
        "        # define target vocabulary size\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        inputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        hidden = self.encoder(src)\n",
        "        hidden=hidden\n",
        "        # get actual answer\n",
        "        input = trg[0,:]\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(input, hidden)\n",
        "            # get the output generated by decoder\n",
        "            outputs[t] = output\n",
        "\n",
        "            truth_force = random.random() < truth_chance\n",
        "            # get top probability value from generated predictions\n",
        "            top1 = output.max(1)[1]\n",
        "            # assign true answer as input if truth chance else assign the previous word top probability generated\n",
        "            input = (trg[t] if truth_force else top1.detach())\n",
        "        return outputs\n",
        "  # define hyperparameters\n",
        "  input_dimension = len(SRC.vocab)\n",
        "  output_dimension = len(TRG.vocab)\n",
        "  embedding_dimension = 300\n",
        "  encoder_hidden_units = 512\n",
        "  decoder_hidden_units = 512\n",
        "  num_layers = 1\n",
        "  dropout_rate = 0.2\n",
        "\n",
        "  encoder = Encoder(input_dimension, embedding_dimension, encoder_hidden_units, num_layers, dropout_rate, enc_embeddings_weights)\n",
        "\n",
        "  decoder = Decoder(output_dimension, embedding_dimension, decoder_hidden_units, num_layers, dropout_rate, dec_embeddings_weights)\n",
        "\n",
        "  model = Seq2Seq_GRU(encoder, decoder, device).to(device)\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "t4_ysfbZnYDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# call model object fucntion that will build model architecture\n",
        "model= model_obj(SRC, TRG, enc_embeddings_weights, dec_embeddings_weights,device)\n",
        "\n",
        "PAD_IDX = SRC.vocab.stoi['<pad>']\n",
        "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
        "# define optimizer and loss function that model will use\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
        "criterion = nn.NLLLoss(ignore_index = PAD_IDX)"
      ],
      "metadata": {
        "id": "28hqLpzADnjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Model train function**"
      ],
      "metadata": {
        "id": "kUZeRao6ENCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    model.train() \n",
        "    epoch_loss = 0\n",
        "\n",
        "    # iterate over all instances in the dataset\n",
        "    for i, batch in enumerate(iterator):\n",
        "        loss_iter=0\n",
        "\n",
        "        src = batch.que_context.to(device)\n",
        "        trg = batch.answer.to(device)\n",
        "        # set all model gradients to zero thaat will be updated during model training\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg)\n",
        "        # reshape the output to get predictions\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "        # calculate the loss, that finds the difference between original and generated predicted values\n",
        "        loss = criterion(output, trg)\n",
        "        # start backpropagation\n",
        "        loss.backward()\n",
        "        # apply optimizer to lower the loss\n",
        "        optimizer.step()\n",
        "        # add loss for each batch\n",
        "        epoch_loss += loss.item()\n",
        "        # take average loss of all batches in one epoch\n",
        "        train_loss = epoch_loss / len(iterator)\n",
        "    # return train loss of one epoch (average of all batches in one epoch)\n",
        "    return train_loss"
      ],
      "metadata": {
        "id": "mFAPGcnJEyKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Model evaluation function**"
      ],
      "metadata": {
        "id": "YaYohGZ7ESFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    # no gradients will be updated during evaluation\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch.que_context.to(device)\n",
        "            trg = batch.answer.to(device)\n",
        "            output = model(src, trg, 0)\n",
        "            # reshape generated predictions\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "            # evaluate loss\n",
        "            loss = criterion(output, trg)\n",
        "            # no optimization is used in evaluation phase\n",
        "            epoch_loss += loss.item()\n",
        "            # average validation loss for all batches in on epoch\n",
        "            validation_loss = epoch_loss / len(iterator)\n",
        "    return validation_loss"
      ],
      "metadata": {
        "id": "5yWYKugLFelt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model,epoch, optimizer, train_loss, valid_loss, direc_path):\n",
        "  model_save_dir = direc_path\n",
        "  file_name = 'model_checkpoint.pt'\n",
        "  path=os.path.join(model_save_dir, file_name)\n",
        "  state = {'epoch': epoch + 1, 'state_dict': model.state_dict(),\n",
        "             'optimizer': optimizer.state_dict(), 'train_loss': train_loss, 'valid_loss' : valid_loss }\n",
        "  \n",
        "  return torch.save(state, path)"
      ],
      "metadata": {
        "id": "iSeW4KH6Fh2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(model, filename):\n",
        "    file_name = filename\n",
        "    PATH=os.path.join(folder_path,file_name)\n",
        "    if os.path.isfile(PATH):\n",
        "        print(\"Loading checkpoint from ----> \", PATH)\n",
        "        checkpoint = torch.load(PATH)\n",
        "        # get current epoch number\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        # get current train loss\n",
        "        train_loss = checkpoint['train_loss']\n",
        "        # get current validation loss\n",
        "        valid_loss = checkpoint['valid_loss']\n",
        "        print(\"Loaded checkpoint\")\n",
        "    else:\n",
        "        print(\"No checkpoint found at: \", filename)\n",
        "\n",
        "    # return parameters current values\n",
        "    return model, optimizer, start_epoch, train_loss, valid_loss"
      ],
      "metadata": {
        "id": "OWuy6friFsGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Start model training**\n",
        "  - **As we can see that train loss is continuously decreasing whereas validation loss is increasing, that shows that model is overfitting**\n",
        "  - **Main reason for model overfitting is we have very small dataset**"
      ],
      "metadata": {
        "id": "c8GCrigeEX0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 10\n",
        "epoch=0\n",
        "best_valid_loss = float('inf')\n",
        "print('\\n\\tStart Model Training',\"-\"*20,\"\\n\")\n",
        "for epoch in range(epoch,max_epochs):\n",
        "      # call train function to perform model training\n",
        "      training_loss = train(model, train_iterator, optimizer, criterion)\n",
        "      # call evaluate function to perform model validation\n",
        "      validation_loss = evaluate(model, valid_iterator, criterion)\n",
        "      # save model pass current parameters values\n",
        "      save_model(model,epoch, optimizer, training_loss, validation_loss, folder_path)\n",
        "      print(\"Epoch: \", epoch+1)\n",
        "      print(\"Train Loss: \", training_loss)\n",
        "      print(\"Validation Loss: \", validation_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M7yTCMJngWv",
        "outputId": "d57d0ffe-7378-4935-d904-65dea4815733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tStart Model Training -------------------- \n",
            "\n",
            "Epoch:  1\n",
            "Train Loss:  5.558204601945835\n",
            "Validation Loss:  5.662248134613037\n",
            "Epoch:  2\n",
            "Train Loss:  5.008569371752343\n",
            "Validation Loss:  6.214366995769998\n",
            "Epoch:  3\n",
            "Train Loss:  3.9987595596688283\n",
            "Validation Loss:  6.171025255452031\n",
            "Epoch:  4\n",
            "Train Loss:  2.6103860212725842\n",
            "Validation Loss:  7.018138118412184\n",
            "Epoch:  5\n",
            "Train Loss:  1.3325079815486633\n",
            "Validation Loss:  7.592483831488567\n",
            "Epoch:  6\n",
            "Train Loss:  0.7202417590212093\n",
            "Validation Loss:  8.140052919802459\n",
            "Epoch:  7\n",
            "Train Loss:  0.4613031075584121\n",
            "Validation Loss:  7.994200934534487\n",
            "Epoch:  8\n",
            "Train Loss:  0.2924839135363096\n",
            "Validation Loss:  8.545173645019531\n",
            "Epoch:  9\n",
            "Train Loss:  0.19694720310317637\n",
            "Validation Loss:  8.462818746981414\n",
            "Epoch:  10\n",
            "Train Loss:  0.11346793245202882\n",
            "Validation Loss:  8.451737341673478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load model from checkpoint\n",
        "model_path = folder_path+\"/model_checkpoint.pt\""
      ],
      "metadata": {
        "id": "j-Psa7BxXAJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, optimizer, epoch, train_loss, valid_loss = load_checkpoint(model, model_path)\n",
        "print(\"\\nloaded parm\")  \n",
        "\n",
        "model.eval()\n",
        "test_data_loss=0\n",
        "pred_list=[]\n",
        "ref_list=[]\n",
        "# set gradients to false\n",
        "with torch.no_grad():\n",
        "  # iterate over test data\n",
        "  for i, batch in enumerate(test_iterator):\n",
        "    #  extract input and output batch\n",
        "    src = batch.que_context.to(device)\n",
        "    trg = batch.answer.to(device)\n",
        "    # apply model on test batches\n",
        "    output = model(src, trg, 0) \n",
        "    output = output[1:].view(-1, output.shape[-1])\n",
        "    trg = trg[1:].view(-1)\n",
        "    # evaluate loss\n",
        "    test_loss = criterion(output, trg)\n",
        "    # get the predicted value having highest probability\n",
        "    topv, topi = output.data.topk(1)\n",
        "    # map original answer indices back to original words from vocabulary\n",
        "    target = ' '.join([TRG.vocab.itos[o] for o in trg if (o != 3 and o != 1 )])\n",
        "    prediction = ' '.join([TRG.vocab.itos[o] for o in topi[:,0] if o!= 3])\n",
        "    # append all predictions and original answers in lists\n",
        "    pred_list.append(prediction)\n",
        "    ref_list.append(target)\n",
        "    # add loss of all batches\n",
        "    test_data_loss+=test_loss\n",
        "  # average loss of al batches\n",
        "  test_data_loss=test_data_loss/len(test_iterator)\n",
        "  print(\"Test Loss: \", test_data_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz7VcBZo3w5I",
        "outputId": "676940bb-0056-46e8-96c2-2addc61462ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "loaded parm\n",
            "Test Loss:  tensor(7.9950, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to evaluate bleu scores of predicted answeres vs original answers\n",
        "def evaluate_blue_score(actual, prediction):\n",
        "  results = dict()\n",
        "  bleu_score1 = 0\n",
        "  bleu_score2 = 0\n",
        "  bleu_score3 = 0\n",
        "  bleu_score4 = 0\n",
        "  # make sure length of predictions and actual answers match so no index will create wrong decision\n",
        "  if len(actual) == len(prediction):\n",
        "    # iterate over all predicitons\n",
        "    for i in range(len(actual)):\n",
        "      # if predicted string is null value return all zeros\n",
        "      if prediction == \"\":\n",
        "        return 0,0,0,0\n",
        "      actual_tokenized = list(map(lambda x: indic_tokenize.trivial_tokenize(x), actual[i]))\n",
        "      pred_tokenized = indic_tokenize.trivial_tokenize(prediction[i])\n",
        "      chencherry = SmoothingFunction()\n",
        "      # nltk functions to calculate bleu1, bleu2, bleu3 and bleu4 score\n",
        "      bleu_1 = sentence_bleu(actual_tokenized, pred_tokenized, weights=(1, 0, 0, 0), smoothing_function=chencherry.method2)\n",
        "      bleu_2 = sentence_bleu(actual_tokenized, pred_tokenized, weights=(0.5, 0.5, 0, 0), smoothing_function=chencherry.method2)\n",
        "      bleu_3 = sentence_bleu(actual_tokenized, pred_tokenized, weights=(0.33, 0.33, 0.33, 0), smoothing_function=chencherry.method2)\n",
        "      bleu_4 = sentence_bleu(actual_tokenized, pred_tokenized, weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=chencherry.method2)\n",
        "      # add up scores of each instance\n",
        "      bleu_score1 +=bleu_1\n",
        "      bleu_score2 +=bleu_2\n",
        "      bleu_score3 +=bleu_3\n",
        "      bleu_score4 +=bleu_4\n",
        "    # convert decimale values  bleu scores to percentage\n",
        "    results[\"bleu_1\"] = [round(bleu_score1 / len(actual) * 100, 2)]\n",
        "    results[\"bleu_2\"] = [round(bleu_score2 / len(actual) * 100, 2)]\n",
        "    results[\"bleu_3\"] = [round(bleu_score3 / len(actual) * 100, 2)]\n",
        "    results[\"bleu_4\"] = [round(bleu_score4 / len(actual) * 100, 2)]\n",
        "    # return total evaluated results\n",
        "    return results\n",
        "  else:\n",
        "    print(\"Error: Actual values and predictions are not of same length....\")\n"
      ],
      "metadata": {
        "id": "UrZHA5bIXieI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "from indicnlp.tokenize import indic_tokenize \n",
        "from deep_translator import GoogleTranslator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSMVPVu0Yfds",
        "outputId": "6e88222d-e0c0-4ec6-dd72-d30181be71ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = [i[:10] for i in pred_list]"
      ],
      "metadata": {
        "id": "GDzt_U8wOZ9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate bleu scores\n",
        "actual_answers = [[i] for i in ref_list]\n",
        "ans_results = evaluate_blue_score(actual_answers, pred)\n",
        "pd.DataFrame(ans_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "uhsI2fJGOS0s",
        "outputId": "e6e7607e-fc7a-4476-ffab-c89200bf57e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   bleu_1  bleu_2  bleu_3  bleu_4\n",
              "0    4.11    4.11    3.98     3.9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-db7ba480-6223-40be-9b9a-4dcfe713f338\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bleu_1</th>\n",
              "      <th>bleu_2</th>\n",
              "      <th>bleu_3</th>\n",
              "      <th>bleu_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.11</td>\n",
              "      <td>4.11</td>\n",
              "      <td>3.98</td>\n",
              "      <td>3.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-db7ba480-6223-40be-9b9a-4dcfe713f338')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-db7ba480-6223-40be-9b9a-4dcfe713f338 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-db7ba480-6223-40be-9b9a-4dcfe713f338');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(ref_list)):\n",
        "  print(\"\\n----------------------------------\\n\")\n",
        "  print(\"Actual answers: \",actual_answers[i][0])\n",
        "  print(\"Predicted answer: \",pred[i])\n",
        "  try:\n",
        "    print(\"Translated Answer: \",GoogleTranslator(source='auto', target='en').translate(pred[i]))\n",
        "  except:\n",
        "    print(\"Translated Answer: \",pred[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUfMlirnZY-O",
        "outputId": "76416a56-8cbd-4b59-f46e-f518e712401f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  उत्तरी\n",
            "Predicted answer:  हिन्दू दिल\n",
            "Translated Answer:  hindu heart\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  உலான் பாட்டர்\n",
            "Predicted answer:  हिन्दू இரு\n",
            "Translated Answer:  Be a Hindu\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  २७ अक्तूबर १६०५\n",
            "Predicted answer:  22 जनवरी 1\n",
            "Translated Answer:  22 Jan 1\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  वेदव्यास\n",
            "Predicted answer:  महर्षि दिल\n",
            "Translated Answer:  Maharishi Dil\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  சீஸ்மோகிராப்\n",
            "Predicted answer:  லூயிஸ்\n",
            "Translated Answer:  Louis\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  अपसौर\n",
            "Predicted answer:  १४९६००००० \n",
            "Translated Answer:  १४९६०००००\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  epistemology\n",
            "Predicted answer:  22 இருப்பத\n",
            "Translated Answer:  22 is absent\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  16579 சதுர கிலோ மீட்டர்\n",
            "Predicted answer:  அத்தானோடு \n",
            "Translated Answer:  With it\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  जेमिमा गोल्डस्मिथ\n",
            "Predicted answer:  पाकिस्तान \n",
            "Translated Answer:  Pakistan\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  2330 मील\n",
            "Predicted answer:  नौ उत्तरदा\n",
            "Translated Answer:  nine answers\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  5 டிசம்பர் 2016\n",
            "Predicted answer:  சென்னை மாக\n",
            "Translated Answer:  Chennai Maga\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  रुडॉल्फ विर्चो\n",
            "Predicted answer:  केशव शंकर \n",
            "Translated Answer:  Keshav Shankar\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  चंदर वोहरा\n",
            "Predicted answer:  जार्ज இருப\n",
            "Translated Answer:  George II\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  யூஜீன் வூசுட்டர்\n",
            "Predicted answer:  ஆடம் उत्तर\n",
            "Translated Answer:  Adam replied\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  ரெயால்\n",
            "Predicted answer:  नौ जिलों उ\n",
            "Translated Answer:  Nine districts n\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  kwh\n",
            "Predicted answer:  26 जनवरी २\n",
            "Translated Answer:  26 Jan 2\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  12092\n",
            "Predicted answer:  206 இருப்ப\n",
            "Translated Answer:  206 existence\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  5 जून 1974\n",
            "Predicted answer:  5 जून\n",
            "Translated Answer:  June 5\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  दीपा मलिक\n",
            "Predicted answer:  हिन्दू बीच\n",
            "Translated Answer:  Hindu Beach\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  फरवरी १९४२\n",
            "Predicted answer:  मुंबई महार\n",
            "Translated Answer:  Mumbai Mahar\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  भारतीय संविधान भाग ४ अनुच्छेद ४४\n",
            "Predicted answer:  हिन्दू उत्\n",
            "Translated Answer:  Hindu origin\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  தோக்கியோ\n",
            "Predicted answer:  அத்தானோடு \n",
            "Translated Answer:  With it\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  भोजदेव\n",
            "Predicted answer:  20770 கிமீ\n",
            "Translated Answer:  20770 km\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  கெய்ரோ\n",
            "Predicted answer:  கிசா हिंसा\n",
            "Translated Answer:  Giza violence\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  एसीनोनिक्स जुबेटस\n",
            "Predicted answer:  हेमीसिर्कस\n",
            "Translated Answer:  hemicircus\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  22 अगस्त 1818\n",
            "Predicted answer:  22 जनवरी २\n",
            "Translated Answer:  22 Jan 2\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  29\n",
            "Predicted answer:  1229 இருப்\n",
            "Translated Answer:  1229 BC\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  होनियारा\n",
            "Predicted answer:  பிரிட்டனில\n",
            "Translated Answer:  In Britain\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  एवरेस्ट पर्वत\n",
            "Predicted answer:  கிமு ஐந்தா\n",
            "Translated Answer:  Five BC\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  चार्ल्स बैबेज\n",
            "Predicted answer:  चार्ल्स बै\n",
            "Translated Answer:  Charles Bai\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  इन्द्र\n",
            "Predicted answer:  ब्रह्मा बच\n",
            "Translated Answer:  Brahma Bach\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  स्विटजरलैंड जेनेवा शहर\n",
            "Predicted answer:  7 अप्रैल 1\n",
            "Translated Answer:  7 April 1\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  किशोरी सिन्हा\n",
            "Predicted answer:  5 जून बच्च\n",
            "Translated Answer:  5 june kids\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  603628 किलोमीटर\n",
            "Predicted answer:  14000000 क\n",
            "Translated Answer:  14000000 k\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  अभिनव भारत सोसायटी\n",
            "Predicted answer:  हिन्दू उत्\n",
            "Translated Answer:  Hindu origin\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  अप्रैल जुलाई\n",
            "Predicted answer:  हिन्दू एक्\n",
            "Translated Answer:  Hindu Ex\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  பத்தனம்தித்தா\n",
            "Predicted answer:  பெங்களூரில\n",
            "Translated Answer:  In Bangalore\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  व्हेरोला व्हेरोला वेरा\n",
            "Predicted answer:  ऐक़्वस फ़े\n",
            "Translated Answer:  Equus Fe\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  बामाक्षेपा\n",
            "Predicted answer:  नलिनीकांत \n",
            "Translated Answer:  Nalinikanth\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  கிபி 11\n",
            "Predicted answer:  பிறப்பு14 \n",
            "Translated Answer:  Birth 14\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  1945\n",
            "Predicted answer:  1914 हिंसा\n",
            "Translated Answer:  1914 Violence\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  मेगा फ्लॉप\n",
            "Predicted answer:  24 சதுர கி\n",
            "Translated Answer:  24 sq. km\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  ventriloquism\n",
            "Predicted answer:  १२ இருப்பத\n",
            "Translated Answer:  12\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  आठ\n",
            "Predicted answer:  आयानमंडल उ\n",
            "Translated Answer:  ionosphere u\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  एडोल्फ मेयर\n",
            "Predicted answer:  हिमाचल उत्\n",
            "Translated Answer:  Himachal Pradesh\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  கி அமர்நாத் ராமகிருஷ்ணன்\n",
            "Predicted answer:  அத்தானோடு \n",
            "Translated Answer:  With it\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  नाथूराम गोडसे\n",
            "Predicted answer:  सुनील मित्\n",
            "Translated Answer:  Sunil Mitt\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  लैरी सेंगर जिम्मी वेल्स\n",
            "Predicted answer:  15 जनवरी 2\n",
            "Translated Answer:  15 Jan 2\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  001 10 नैनोमीटर\n",
            "Predicted answer:  प्रेम हिंस\n",
            "Translated Answer:  Prem Hins\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  1917ஆம் ஆண்டு நவம்பர் 19\n",
            "Predicted answer:  கிமு ஐந்தா\n",
            "Translated Answer:  Five BC\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  सम्राट सूर्यवर्मन द्वितीय\n",
            "Predicted answer:  लालेमें बच\n",
            "Translated Answer:  escape in red\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  १४९६००००० किलोमीटर\n",
            "Predicted answer:  1312 भारत \n",
            "Translated Answer:  1312 India\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  १९५४ ई\n",
            "Predicted answer:  भारतीय சது\n",
            "Translated Answer:  Indian Sq\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  கிமு 356 ஆம் ஆண்டு சூலை மாதம் 6\n",
            "Predicted answer:  अफ्रीकी दि\n",
            "Translated Answer:  African day\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  174 கிமீ²\n",
            "Predicted answer:  86928 சதுர\n",
            "Translated Answer:  86928 Sq\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  नई दिल्ली\n",
            "Predicted answer:  मिर्ज़ा ख़\n",
            "Translated Answer:  mirza kh\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  1917ஆம் ஆண்டு நவம்பர் 19\n",
            "Predicted answer:  கிமு ஐந்தா\n",
            "Translated Answer:  Five BC\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  15 कि॰मी॰ लम्बा 7 कि॰मी॰ चौड़ा\n",
            "Predicted answer:  97776 किलो\n",
            "Translated Answer:  97776 kg\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  दक्षिणी अफ्रीका\n",
            "Predicted answer:  हिन्दू शहर\n",
            "Translated Answer:  Hindu city\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  1825\n",
            "Predicted answer:  2006 சதுர \n",
            "Translated Answer:  2006 Sq\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  चार्ल्स लुई अल्फोंस लैवेरन\n",
            "Predicted answer:  केशव शंकर \n",
            "Translated Answer:  Keshav Shankar\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  7ம் நூற்றாண்டில்\n",
            "Predicted answer:  எகிப்தின் \n",
            "Translated Answer:  of Egypt\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  1861\n",
            "Predicted answer:  12 जनवरी 2\n",
            "Translated Answer:  12 Jan 2\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  नेताजी\n",
            "Predicted answer:  बीबी हिंसा\n",
            "Translated Answer:  bibi violence\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  भारत\n",
            "Predicted answer:  १४८४ उत्तर\n",
            "Translated Answer:  1484 Answer\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  14799 கிமீ\n",
            "Predicted answer:  स्पेनी சது\n",
            "Translated Answer:  Spanish Square\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  १२ अक्टुबर १९७२\n",
            "Predicted answer:  7 ईपू उत्त\n",
            "Translated Answer:  7 BC North\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  सिर\n",
            "Predicted answer:  तंत्रिका ப\n",
            "Translated Answer:  nerve\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  आन्ध्र प्रदेश\n",
            "Predicted answer:  आन्ध्र प्र\n",
            "Translated Answer:  Andhra Pradesh\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  1944\n",
            "Predicted answer:  7 उत्तरदाय\n",
            "Translated Answer:  7 Responsibilities\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  7 अप्रैल 1948\n",
            "Predicted answer:  7 अप्रैल 1\n",
            "Translated Answer:  7 April 1\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  ३२४ मीटर\n",
            "Predicted answer:  ३२४ मीटर क\n",
            "Translated Answer:  324 m\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  1977\n",
            "Predicted answer:  கிமு ஐந்தா\n",
            "Translated Answer:  Five BC\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  208\n",
            "Predicted answer:  208 இருப்ப\n",
            "Translated Answer:  208 existence\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  072 एयू\n",
            "Predicted answer:  பிரிட்டனில\n",
            "Translated Answer:  In Britain\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  इमरान ख़ान\n",
            "Predicted answer:  मराठी बच्च\n",
            "Translated Answer:  marathi kids\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  பெங்களூரு\n",
            "Predicted answer:  சென்னை बच्\n",
            "Translated Answer:  Chennai Child\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  एम्पीयर\n",
            "Predicted answer:  जार्ज\n",
            "Translated Answer:  George\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  32\n",
            "Predicted answer:  लाल लिटर ह\n",
            "Translated Answer:  red litter\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  1964\n",
            "Predicted answer:  ३० जनवरी १\n",
            "Translated Answer:  30 Jan 1\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  मोहम्मद बिन सलमान अल सऊद\n",
            "Predicted answer:  मराठी இருப\n",
            "Translated Answer:  Marathi Bi\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  கூபு\n",
            "Predicted answer:  மயில் बच्च\n",
            "Translated Answer:  Peacock baby\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  70\n",
            "Predicted answer:  70 बच्चन उ\n",
            "Translated Answer:  70 Bachchan U\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  ८३ मिनट\n",
            "Predicted answer:  १४९६००००० \n",
            "Translated Answer:  १४९६०००००\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  39202\n",
            "Predicted answer:  24 இருப்பத\n",
            "Translated Answer:  24 is not present\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  210 किलोमीटर\n",
            "Predicted answer:  194 दिल्ली\n",
            "Translated Answer:  194 Delhi\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  1948\n",
            "Predicted answer:  1968 दिल्ल\n",
            "Translated Answer:  1968 Delhi\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  बिहार\n",
            "Predicted answer:  महाराष्ट्र\n",
            "Translated Answer:  Maharashtra\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  வட அமெரிக்க\n",
            "Predicted answer:  இரண்டு மில\n",
            "Translated Answer:  Two miles\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  மேரிகியூரி பியரிகியூரி\n",
            "Predicted answer:  1898 दिल्ल\n",
            "Translated Answer:  1898 Delhi\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  अक्टूबर २०१०\n",
            "Predicted answer:  केविन सिस्\n",
            "Translated Answer:  kevin sis\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  chilaka gorinka\n",
            "Predicted answer:  लीला हिंसा\n",
            "Translated Answer:  Leela Violence\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  1924 சூன் 3\n",
            "Predicted answer:  செப்டம்பர்\n",
            "Translated Answer:  September\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  लाहिरी महाशय\n",
            "Predicted answer:  165 17 196\n",
            "Translated Answer:  165 17 196\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  பாயங்\n",
            "Predicted answer:  165 किमी द\n",
            "Translated Answer:  165 km south\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  जर्मनी\n",
            "Predicted answer:  हिन्दू இரு\n",
            "Translated Answer:  Be a Hindu\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  1997\n",
            "Predicted answer:  अज़ीज़ मिर\n",
            "Translated Answer:  Aziz Mir\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  என்றிகோ பெர்மியின்\n",
            "Predicted answer:  அணு எண் 2 \n",
            "Translated Answer:  Atomic number 2\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  कैवेंडिश प्रोफ़ेसर\n",
            "Predicted answer:  பிரிட்டனில\n",
            "Translated Answer:  In Britain\n",
            "\n",
            "----------------------------------\n",
            "\n",
            "Actual answers:  19051921 ஆண்டுகளுக்கிடையில்\n",
            "Predicted answer:  2014 दिल्ल\n",
            "Translated Answer:  2014 Delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t-kvX8tDkxkk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}